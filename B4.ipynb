{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+8kSI6z5t17gKHW6V4MZp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perspectacular/Tensorflow_Certification_Preparation_Dicoding/blob/main/B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQevGf4YKviO"
      },
      "outputs": [],
      "source": [
        "# ===================================================================================================\n",
        "# PROBLEM B4\n",
        "#\n",
        "# Build and train a classifier for the BBC-text dataset.\n",
        "# This is a multiclass classification problem.\n",
        "# Do not use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is originally published in: http://mlg.ucd.ie/datasets/bbc.html.\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 91%\n",
        "# ===================================================================================================   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import csv as csv\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LZy_-OeCkbdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solution_B4():\n",
        "    def fit_tokenizer(train_sentences, num_words, oov_token):\n",
        "        tokenizer = Tokenizer(num_words = num_words, oov_token = oov_token)\n",
        "        tokenizer.fit_on_texts(train_sentences)\n",
        "        return tokenizer\n",
        "\n",
        "    def seq_and_pad(sentences, tokenizer, padding, maxlen):\n",
        "        sequences = tokenizer.texts_to_sequences(sentences) \n",
        "        padded_sequences = pad_sequences(sequences, padding = padding, maxlen = maxlen)\n",
        "        return padded_sequences\n",
        "\n",
        "    def tokenize_labels(all_labels, split_labels):\n",
        "        label_tokenizer = Tokenizer()\n",
        "        label_tokenizer.fit_on_texts(all_labels)\n",
        "        label_seq = np.array(label_tokenizer.texts_to_sequences(split_labels))\n",
        "        label_seq_np = np.array(label_seq) - 1\n",
        "        return label_seq_np\n",
        "    \n",
        "    bbc = pd.read_csv(\n",
        "        'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/bbc-text.csv')\n",
        "    bbc.to_csv('bbc-text.csv', index = False)\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "    \n",
        "    with open('bbc-text.csv', 'r') as csvfile:\n",
        "        ### START CODE HERE\n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        next(reader)\n",
        "        for row in reader:\n",
        "            label = row.pop(0)\n",
        "            labels.append(label)\n",
        "            row = \" \".join(row)\n",
        "            sentence = row.lower()\n",
        "            sentence = sentence.split(\" \")\n",
        "            for stopword in stopwords:\n",
        "                while stopword in sentence:\n",
        "                    sentence.remove(stopword)\n",
        "            sentence=' '.join(sentence)\n",
        "            sentences.append(sentence)\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    # Make sure you used all of these parameters or you can not pass this test\n",
        "    vocab_size = 1000\n",
        "    embedding_dim = 16\n",
        "    max_length = 120\n",
        "    trunc_type = 'post'\n",
        "    padding_type = 'post'\n",
        "    oov_tok = \"<OOV>\"\n",
        "    training_portion = .8\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    # Using \"shuffle=False\"\n",
        "    train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
        "        sentences, \n",
        "        labels, \n",
        "        train_size=training_portion, \n",
        "        shuffle=False\n",
        "    )\n",
        "    # Fit your tokenizer with training data\n",
        "    tokenizer =  Tokenizer(\n",
        "        num_words=vocab_size, \n",
        "        oov_token=oov_tok\n",
        "    )\n",
        "\n",
        "    tokenizer.fit_on_texts(train_sentences)\n",
        "    word_index = tokenizer.word_index\n",
        "    train_padded_seq = seq_and_pad(train_sentences, tokenizer, padding_type, max_length)\n",
        "    val_padded_seq = seq_and_pad(test_sentences, tokenizer, padding_type, max_length)\n",
        "\n",
        "    train_label_seq = tokenize_labels(labels, train_labels)\n",
        "    val_label_seq = tokenize_labels(labels, test_labels)\n",
        "\n",
        "    model = tf.keras.Sequential([ \n",
        "        tf.keras.layers.Embedding(\n",
        "            vocab_size,\n",
        "            embedding_dim, \n",
        "            input_length=max_length),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        tf.keras.layers.Dense(24, activation='relu'),\n",
        "        tf.keras.layers.Dense(6, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy']) \n",
        "    model.fit(\n",
        "        train_padded_seq, \n",
        "        train_label_seq, \n",
        "        epochs=300, \n",
        "        validation_data=(val_padded_seq, val_label_seq)\n",
        "    )    \n",
        "\n",
        "    # Make sure you are using \"sparse_categorical_crossentropy\" as a loss fuction\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "S3zdN6Pokbm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_B4()\n",
        "    model.save(\"model_B4.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq4fSAdxkXUx",
        "outputId": "12f38274-7d86-474f-cad8-5b268abc4283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "56/56 [==============================] - 1s 6ms/step - loss: 1.7620 - accuracy: 0.2303 - val_loss: 1.7239 - val_accuracy: 0.2787\n",
            "Epoch 2/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6713 - accuracy: 0.4152 - val_loss: 1.6143 - val_accuracy: 0.2652\n",
            "Epoch 3/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.5361 - accuracy: 0.4494 - val_loss: 1.4637 - val_accuracy: 0.6045\n",
            "Epoch 4/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3549 - accuracy: 0.6489 - val_loss: 1.2747 - val_accuracy: 0.6427\n",
            "Epoch 5/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1551 - accuracy: 0.6961 - val_loss: 1.0881 - val_accuracy: 0.7663\n",
            "Epoch 6/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.9731 - accuracy: 0.8022 - val_loss: 0.9300 - val_accuracy: 0.7865\n",
            "Epoch 7/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.8202 - accuracy: 0.8202 - val_loss: 0.7992 - val_accuracy: 0.8157\n",
            "Epoch 8/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.8545 - val_loss: 0.7004 - val_accuracy: 0.8607\n",
            "Epoch 9/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.8826 - val_loss: 0.6090 - val_accuracy: 0.8674\n",
            "Epoch 10/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.9006 - val_loss: 0.5437 - val_accuracy: 0.8719\n",
            "Epoch 11/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.9135 - val_loss: 0.4893 - val_accuracy: 0.8831\n",
            "Epoch 12/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.9264 - val_loss: 0.4439 - val_accuracy: 0.8944\n",
            "Epoch 13/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.9331 - val_loss: 0.4081 - val_accuracy: 0.9011\n",
            "Epoch 14/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.9421 - val_loss: 0.3775 - val_accuracy: 0.9011\n",
            "Epoch 15/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.2582 - accuracy: 0.9478 - val_loss: 0.3535 - val_accuracy: 0.9011\n",
            "Epoch 16/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9517 - val_loss: 0.3302 - val_accuracy: 0.9146\n",
            "Epoch 17/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9596 - val_loss: 0.3107 - val_accuracy: 0.9191\n",
            "Epoch 18/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1804 - accuracy: 0.9669 - val_loss: 0.2926 - val_accuracy: 0.9124\n",
            "Epoch 19/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.9691 - val_loss: 0.2818 - val_accuracy: 0.9191\n",
            "Epoch 20/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9764 - val_loss: 0.2707 - val_accuracy: 0.9258\n",
            "Epoch 21/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9815 - val_loss: 0.2606 - val_accuracy: 0.9236\n",
            "Epoch 22/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1171 - accuracy: 0.9843 - val_loss: 0.2530 - val_accuracy: 0.9258\n",
            "Epoch 23/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9843 - val_loss: 0.2440 - val_accuracy: 0.9236\n",
            "Epoch 24/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9888 - val_loss: 0.2395 - val_accuracy: 0.9258\n",
            "Epoch 25/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9904 - val_loss: 0.2334 - val_accuracy: 0.9236\n",
            "Epoch 26/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9921 - val_loss: 0.2294 - val_accuracy: 0.9213\n",
            "Epoch 27/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9933 - val_loss: 0.2272 - val_accuracy: 0.9213\n",
            "Epoch 28/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9933 - val_loss: 0.2232 - val_accuracy: 0.9213\n",
            "Epoch 29/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9949 - val_loss: 0.2195 - val_accuracy: 0.9213\n",
            "Epoch 30/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9961 - val_loss: 0.2181 - val_accuracy: 0.9236\n",
            "Epoch 31/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9961 - val_loss: 0.2137 - val_accuracy: 0.9258\n",
            "Epoch 32/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9972 - val_loss: 0.2160 - val_accuracy: 0.9258\n",
            "Epoch 33/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9972 - val_loss: 0.2113 - val_accuracy: 0.9258\n",
            "Epoch 34/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9978 - val_loss: 0.2098 - val_accuracy: 0.9236\n",
            "Epoch 35/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9978 - val_loss: 0.2078 - val_accuracy: 0.9281\n",
            "Epoch 36/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9978 - val_loss: 0.2072 - val_accuracy: 0.9258\n",
            "Epoch 37/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9978 - val_loss: 0.2087 - val_accuracy: 0.9236\n",
            "Epoch 38/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9983 - val_loss: 0.2082 - val_accuracy: 0.9281\n",
            "Epoch 39/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9983 - val_loss: 0.2065 - val_accuracy: 0.9258\n",
            "Epoch 40/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9989 - val_loss: 0.2059 - val_accuracy: 0.9281\n",
            "Epoch 41/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9236\n",
            "Epoch 42/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9303\n",
            "Epoch 43/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9303\n",
            "Epoch 44/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9281\n",
            "Epoch 45/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9258\n",
            "Epoch 46/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9303\n",
            "Epoch 47/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9326\n",
            "Epoch 48/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9303\n",
            "Epoch 49/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9326\n",
            "Epoch 50/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9303\n",
            "Epoch 51/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9326\n",
            "Epoch 52/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9326\n",
            "Epoch 53/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9326\n",
            "Epoch 54/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9326\n",
            "Epoch 55/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9326\n",
            "Epoch 56/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9348\n",
            "Epoch 57/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9348\n",
            "Epoch 58/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9326\n",
            "Epoch 59/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9326\n",
            "Epoch 60/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9348\n",
            "Epoch 61/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9348\n",
            "Epoch 62/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9371\n",
            "Epoch 63/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9348\n",
            "Epoch 64/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9371\n",
            "Epoch 65/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9371\n",
            "Epoch 66/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9371\n",
            "Epoch 67/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9348\n",
            "Epoch 68/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9371\n",
            "Epoch 69/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9371\n",
            "Epoch 70/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9371\n",
            "Epoch 71/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9371\n",
            "Epoch 72/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9371\n",
            "Epoch 73/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9371\n",
            "Epoch 74/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9371\n",
            "Epoch 75/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9371\n",
            "Epoch 76/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9371\n",
            "Epoch 77/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9371\n",
            "Epoch 78/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9371\n",
            "Epoch 79/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9371\n",
            "Epoch 80/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9371\n",
            "Epoch 81/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9371\n",
            "Epoch 82/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9371\n",
            "Epoch 83/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9371\n",
            "Epoch 84/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9393\n",
            "Epoch 85/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9348\n",
            "Epoch 86/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9393\n",
            "Epoch 87/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9348\n",
            "Epoch 88/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9348\n",
            "Epoch 89/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9371\n",
            "Epoch 90/300\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9348\n",
            "Epoch 91/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9371\n",
            "Epoch 92/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9371\n",
            "Epoch 93/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9371\n",
            "Epoch 94/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9348\n",
            "Epoch 95/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9371\n",
            "Epoch 96/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.9619e-04 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9371\n",
            "Epoch 97/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.5490e-04 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9371\n",
            "Epoch 98/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.1529e-04 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9348\n",
            "Epoch 99/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.8041e-04 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9371\n",
            "Epoch 100/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.4657e-04 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9371\n",
            "Epoch 101/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.1017e-04 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9371\n",
            "Epoch 102/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.7886e-04 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9371\n",
            "Epoch 103/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.4669e-04 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9393\n",
            "Epoch 104/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.1869e-04 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9393\n",
            "Epoch 105/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.9040e-04 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9371\n",
            "Epoch 106/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.6303e-04 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9393\n",
            "Epoch 107/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 6.3798e-04 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9393\n",
            "Epoch 108/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.1717e-04 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9393\n",
            "Epoch 109/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.9382e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9393\n",
            "Epoch 110/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 5.6837e-04 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9393\n",
            "Epoch 111/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.4733e-04 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9393\n",
            "Epoch 112/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 5.2518e-04 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9393\n",
            "Epoch 113/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.0547e-04 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9393\n",
            "Epoch 114/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.8705e-04 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9393\n",
            "Epoch 115/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.6867e-04 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9393\n",
            "Epoch 116/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.5117e-04 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9393\n",
            "Epoch 117/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.3524e-04 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9393\n",
            "Epoch 118/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.1822e-04 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9393\n",
            "Epoch 119/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.0259e-04 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9393\n",
            "Epoch 120/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.8979e-04 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9393\n",
            "Epoch 121/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.7405e-04 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9393\n",
            "Epoch 122/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 3.6002e-04 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9393\n",
            "Epoch 123/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.4741e-04 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9393\n",
            "Epoch 124/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.3489e-04 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9393\n",
            "Epoch 125/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.2266e-04 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9393\n",
            "Epoch 126/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 3.1095e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9393\n",
            "Epoch 127/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.9969e-04 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9393\n",
            "Epoch 128/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.8881e-04 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9416\n",
            "Epoch 129/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.7820e-04 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9393\n",
            "Epoch 130/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.6840e-04 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9393\n",
            "Epoch 131/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.5898e-04 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9393\n",
            "Epoch 132/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.4961e-04 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9416\n",
            "Epoch 133/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.4055e-04 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9416\n",
            "Epoch 134/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3241e-04 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9416\n",
            "Epoch 135/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.2408e-04 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9416\n",
            "Epoch 136/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.1658e-04 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9416\n",
            "Epoch 137/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.0874e-04 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9416\n",
            "Epoch 138/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.0106e-04 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9416\n",
            "Epoch 139/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.9436e-04 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9416\n",
            "Epoch 140/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.8764e-04 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9416\n",
            "Epoch 141/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.8135e-04 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9416\n",
            "Epoch 142/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.7488e-04 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9416\n",
            "Epoch 143/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6843e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9416\n",
            "Epoch 144/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6294e-04 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9416\n",
            "Epoch 145/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.5728e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9416\n",
            "Epoch 146/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.5156e-04 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9416\n",
            "Epoch 147/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.4662e-04 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9416\n",
            "Epoch 148/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4150e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9416\n",
            "Epoch 149/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3670e-04 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9416\n",
            "Epoch 150/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.3182e-04 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9416\n",
            "Epoch 151/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2733e-04 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9416\n",
            "Epoch 152/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2297e-04 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9416\n",
            "Epoch 153/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1875e-04 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9416\n",
            "Epoch 154/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1483e-04 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9416\n",
            "Epoch 155/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.1076e-04 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9416\n",
            "Epoch 156/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0707e-04 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9416\n",
            "Epoch 157/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0346e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9416\n",
            "Epoch 158/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0014e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9416\n",
            "Epoch 159/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.6579e-05 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9416\n",
            "Epoch 160/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.3426e-05 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9416\n",
            "Epoch 161/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 9.0355e-05 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9416\n",
            "Epoch 162/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 8.7234e-05 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9416\n",
            "Epoch 163/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.4377e-05 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9416\n",
            "Epoch 164/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.1454e-05 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9416\n",
            "Epoch 165/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.8941e-05 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9416\n",
            "Epoch 166/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 7.6040e-05 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9416\n",
            "Epoch 167/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.3776e-05 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9416\n",
            "Epoch 168/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 7.1025e-05 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9416\n",
            "Epoch 169/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.8790e-05 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9416\n",
            "Epoch 170/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.6387e-05 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9416\n",
            "Epoch 171/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.4179e-05 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9416\n",
            "Epoch 172/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.2075e-05 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9416\n",
            "Epoch 173/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.0123e-05 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9416\n",
            "Epoch 174/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.8097e-05 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9416\n",
            "Epoch 175/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.6099e-05 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9416\n",
            "Epoch 176/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 5.4238e-05 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9416\n",
            "Epoch 177/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 5.2637e-05 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9416\n",
            "Epoch 178/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 5.0765e-05 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.9416\n",
            "Epoch 179/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.9107e-05 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9416\n",
            "Epoch 180/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 4.7471e-05 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9416\n",
            "Epoch 181/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.5879e-05 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9416\n",
            "Epoch 182/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.4374e-05 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9416\n",
            "Epoch 183/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.2902e-05 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9416\n",
            "Epoch 184/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.1514e-05 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9416\n",
            "Epoch 185/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 4.0187e-05 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9416\n",
            "Epoch 186/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.8881e-05 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9416\n",
            "Epoch 187/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.7700e-05 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9416\n",
            "Epoch 188/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.6411e-05 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9416\n",
            "Epoch 189/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 3.5245e-05 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9416\n",
            "Epoch 190/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.4105e-05 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9416\n",
            "Epoch 191/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.3027e-05 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9416\n",
            "Epoch 192/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.1893e-05 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9416\n",
            "Epoch 193/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.0863e-05 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.9416\n",
            "Epoch 194/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.9883e-05 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.9416\n",
            "Epoch 195/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.8896e-05 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9416\n",
            "Epoch 196/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.7952e-05 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9438\n",
            "Epoch 197/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.7068e-05 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9416\n",
            "Epoch 198/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.6215e-05 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9416\n",
            "Epoch 199/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.5359e-05 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9416\n",
            "Epoch 200/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.4528e-05 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.9416\n",
            "Epoch 201/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.3742e-05 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9416\n",
            "Epoch 202/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2994e-05 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.9438\n",
            "Epoch 203/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.2220e-05 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9416\n",
            "Epoch 204/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.1502e-05 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9438\n",
            "Epoch 205/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.0815e-05 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9438\n",
            "Epoch 206/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.0170e-05 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9438\n",
            "Epoch 207/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.9529e-05 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9438\n",
            "Epoch 208/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.8938e-05 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9416\n",
            "Epoch 209/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.8306e-05 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9416\n",
            "Epoch 210/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.7730e-05 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9438\n",
            "Epoch 211/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.7163e-05 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9438\n",
            "Epoch 212/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.6606e-05 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9438\n",
            "Epoch 213/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6093e-05 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9438\n",
            "Epoch 214/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.5552e-05 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9416\n",
            "Epoch 215/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.5081e-05 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9438\n",
            "Epoch 216/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4582e-05 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9438\n",
            "Epoch 217/300\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 1.4133e-05 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9438\n",
            "Epoch 218/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3695e-05 - accuracy: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.9438\n",
            "Epoch 219/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3262e-05 - accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.9438\n",
            "Epoch 220/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2815e-05 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 0.9438\n",
            "Epoch 221/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.2429e-05 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9438\n",
            "Epoch 222/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2034e-05 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9438\n",
            "Epoch 223/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1660e-05 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.9438\n",
            "Epoch 224/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.1269e-05 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9438\n",
            "Epoch 225/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.0898e-05 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9438\n",
            "Epoch 226/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.0580e-05 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.9438\n",
            "Epoch 227/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.0228e-05 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9438\n",
            "Epoch 228/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 9.9146e-06 - accuracy: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.9438\n",
            "Epoch 229/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 9.5921e-06 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.9438\n",
            "Epoch 230/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 9.2807e-06 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9438\n",
            "Epoch 231/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 9.0107e-06 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9438\n",
            "Epoch 232/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.7305e-06 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9438\n",
            "Epoch 233/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 8.4496e-06 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9438\n",
            "Epoch 234/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 8.1931e-06 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9438\n",
            "Epoch 235/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 7.9601e-06 - accuracy: 1.0000 - val_loss: 0.3354 - val_accuracy: 0.9438\n",
            "Epoch 236/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 7.6763e-06 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9438\n",
            "Epoch 237/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 7.4366e-06 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9438\n",
            "Epoch 238/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 7.2174e-06 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 0.9438\n",
            "Epoch 239/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 6.9878e-06 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9438\n",
            "Epoch 240/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 6.7779e-06 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9438\n",
            "Epoch 241/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 6.5583e-06 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9438\n",
            "Epoch 242/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 6.3579e-06 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.9438\n",
            "Epoch 243/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 6.1506e-06 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9438\n",
            "Epoch 244/300\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 5.9754e-06 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9438\n",
            "Epoch 245/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 5.8008e-06 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9438\n",
            "Epoch 246/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 5.6070e-06 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9438\n",
            "Epoch 247/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 5.4290e-06 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9438\n",
            "Epoch 248/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 5.2691e-06 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9438\n",
            "Epoch 249/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 5.1053e-06 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9438\n",
            "Epoch 250/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 4.9436e-06 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9438\n",
            "Epoch 251/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 4.7851e-06 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9438\n",
            "Epoch 252/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 4.6422e-06 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9438\n",
            "Epoch 253/300\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 4.4947e-06 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9438\n",
            "Epoch 254/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 4.3642e-06 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9438\n",
            "Epoch 255/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 4.2357e-06 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9438\n",
            "Epoch 256/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 4.1014e-06 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.9438\n",
            "Epoch 257/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.9704e-06 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9438\n",
            "Epoch 258/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.8501e-06 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9438\n",
            "Epoch 259/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.7301e-06 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9438\n",
            "Epoch 260/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.6292e-06 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9438\n",
            "Epoch 261/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.5065e-06 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9438\n",
            "Epoch 262/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.4100e-06 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.9438\n",
            "Epoch 263/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 3.2996e-06 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9438\n",
            "Epoch 264/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 3.2022e-06 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9438\n",
            "Epoch 265/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 3.1029e-06 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9438\n",
            "Epoch 266/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 3.0077e-06 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9438\n",
            "Epoch 267/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.9136e-06 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.9438\n",
            "Epoch 268/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.8301e-06 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.9438\n",
            "Epoch 269/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.7433e-06 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9438\n",
            "Epoch 270/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.6586e-06 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9438\n",
            "Epoch 271/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.5762e-06 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9438\n",
            "Epoch 272/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.5024e-06 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9438\n",
            "Epoch 273/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.4292e-06 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9438\n",
            "Epoch 274/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.3531e-06 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9438\n",
            "Epoch 275/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.2806e-06 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9438\n",
            "Epoch 276/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.2141e-06 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9438\n",
            "Epoch 277/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.1504e-06 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9438\n",
            "Epoch 278/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 2.0829e-06 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9438\n",
            "Epoch 279/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 2.0212e-06 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9438\n",
            "Epoch 280/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.9607e-06 - accuracy: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.9438\n",
            "Epoch 281/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.9044e-06 - accuracy: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.9438\n",
            "Epoch 282/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.8438e-06 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9438\n",
            "Epoch 283/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.7896e-06 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9438\n",
            "Epoch 284/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.7348e-06 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.9438\n",
            "Epoch 285/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6837e-06 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9438\n",
            "Epoch 286/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.6333e-06 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9438\n",
            "Epoch 287/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.5843e-06 - accuracy: 1.0000 - val_loss: 0.3735 - val_accuracy: 0.9438\n",
            "Epoch 288/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.5387e-06 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9438\n",
            "Epoch 289/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4926e-06 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9438\n",
            "Epoch 290/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4481e-06 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9438\n",
            "Epoch 291/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.4043e-06 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9438\n",
            "Epoch 292/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3650e-06 - accuracy: 1.0000 - val_loss: 0.3771 - val_accuracy: 0.9438\n",
            "Epoch 293/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.3223e-06 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9438\n",
            "Epoch 294/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2856e-06 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.9438\n",
            "Epoch 295/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2494e-06 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9438\n",
            "Epoch 296/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.2152e-06 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9438\n",
            "Epoch 297/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1751e-06 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.9438\n",
            "Epoch 298/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.1436e-06 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9438\n",
            "Epoch 299/300\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.1079e-06 - accuracy: 1.0000 - val_loss: 0.3822 - val_accuracy: 0.9438\n",
            "Epoch 300/300\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0775e-06 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9438\n"
          ]
        }
      ]
    }
  ]
}